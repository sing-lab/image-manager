version: '3.8'

services:
  web:
    build:
      context: .
      dockerfile: Dockerfile
#    command: uvicorn app.main:app --reload --workers 1 --host 0.0.0.0 --port 8080
#    command: python main.py
    command: python -c "import torch;torch.cuda.is_available();torch.cuda.get_device_name(0);"
#    command: python -c "import os; print(os.getenv('NVIDIA_VISIBLE_DEVICES'));"
#    command: python -c "import os; print(os.getenv('LD_LIBRARY_PATH'));"
#    command: python -c "import os; print(os.getenv('CUDA_VERSION'));"
#    command: python -c "import os, sys; print(os.getenv('PATH'));"
#    command: nvcc --version
#    command: nvidia-smi
    volumes:
      - ../api/app/static/images:/app/data_container
    ports:
      - "5000:5000"
#  test:
#    image: nvidia/cuda:11.3.0-cudnn8-devel
#    command: nvidia-smi
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: 1
#              capabilities: [gpu]
#    image: pytorch/pytorch:1.10.0-cuda11.3-cudnn8-runtime
#    environment:
#      NVIDIA_VISIBLE_DEVICES: "all"
#      NVIDIA_DRIVER_CAPABILITIES: "compute"
#      CUDA_VISIBLE_DEVICES: "0"
#      PATH: "/usr/local/nvidia/bin"
#    command: nvidia-smi
#    command: python -c "import torch;torch.cuda.is_available();torch.cuda.get_device_name(0);"
#    command: python -c "import sys;print(sys.path)"
##    deploy:
#      resources:
#        reservations:
#          devices:
#            - capabilities: [gpu]
